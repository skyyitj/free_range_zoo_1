/home/liuchi/miniconda3/envs/zymatch/lib/python3.12/site-packages/torch/nested/__init__.py:109: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)
  return torch._nested_tensor_from_tensor_list(ts, dtype, None, device, None)
Traceback (most recent call last):
  File "/home/liuchi/yitianjiao/aamas2025/free-range-zoo/free_range_zoo/experiments/train.py", line 74, in <module>
    agent_name: agents[agent_name].act(action_space=env.action_space(agent_name))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liuchi/yitianjiao/aamas2025/free-range-zoo/free_range_zoo/envs/wildfire/baselines/generated_agent.py", line 29, in act
    fire_intensity = self.observation['tasks'][:, :, 2]  # Intensity of the fires in each grid position
                     ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
NotImplementedError: Could not run 'aten::slice.Tensor' with arguments from the 'NestedTensorCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::slice.Tensor' is only available for these backends: [CPU, CUDA, HIP, XLA, MPS, IPU, XPU, HPU, VE, Lazy, MTIA, PrivateUse1, PrivateUse2, PrivateUse3, Meta, FPGA, MAIA, Vulkan, Metal, QuantizedCPU, QuantizedCUDA, QuantizedHIP, QuantizedXLA, QuantizedMPS, QuantizedIPU, QuantizedXPU, QuantizedHPU, QuantizedVE, QuantizedLazy, QuantizedMTIA, QuantizedPrivateUse1, QuantizedPrivateUse2, QuantizedPrivateUse3, QuantizedMeta, CustomRNGKeyId, MkldnnCPU, SparseCPU, SparseCUDA, SparseHIP, SparseXLA, SparseMPS, SparseIPU, SparseXPU, SparseHPU, SparseVE, SparseLazy, SparseMTIA, SparsePrivateUse1, SparsePrivateUse2, SparsePrivateUse3, SparseMeta, SparseCsrCPU, SparseCsrCUDA, SparseCsrHIP, SparseCsrXLA, SparseCsrMPS, SparseCsrIPU, SparseCsrXPU, SparseCsrHPU, SparseCsrVE, SparseCsrLazy, SparseCsrMTIA, SparseCsrPrivateUse1, SparseCsrPrivateUse2, SparseCsrPrivateUse3, SparseCsrMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].

Undefined: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
CPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
CUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
HIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
XLA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
MPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
IPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
XPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
HPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
VE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
Lazy: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
MTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
PrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
PrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
PrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
Meta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
FPGA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
MAIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
Vulkan: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
Metal: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedXLA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedLazy: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
QuantizedMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
CustomRNGKeyId: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
MkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseXLA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseLazy: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparsePrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparsePrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparsePrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrXLA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrLazy: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
SparseCsrMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp:8515 [default backend kernel]
BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]
FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]
Functionalize: registered at /pytorch/build/aten/src/ATen/RegisterFunctionalization_2.cpp:23834 [kernel]
Named: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]
Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]
Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]
ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]
ADInplaceOrView: registered at /pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4942 [kernel]
AutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
AutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]
Tracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_4.cpp:13493 [kernel]
AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]
AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]
AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]
AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]
FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/BatchRulesViews.cpp:555 [kernel]
BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]
FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]
Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]
VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]
FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]
PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]
PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]
PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]

