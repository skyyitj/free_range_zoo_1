After analyzing the performance metrics, slight improvements in various areas may yield better results. Specifically, the suppressant efficiency could be increased to make better use of the resources available to each agent.

Let's take into account the following changes:

- **Rewards**: High rewards suggest that the agents are functioning effectively. However, this can be pushed further by optimizing the use of resources and minimizing distances covered.
- **Fire Intensity Change**: A negative change in fire intensity suggests successful firefighting. This metric can be improved through addressing high intensity fires more urgently.
- **Suppressant Efficiency**: Although the current efficiency is good, there's a need for higher efficiency to improve resource utilization.

Given that, let's make the following changes:
- We will increase the conservation factor of the suppressant to promote its better usage and, thus, improve the overall efficiency.
- Adjust the temperature parameters to increase focus on depth and decrease focus on distance.

Here is the modified policy function based on the analysis:

```python
import numpy as np

def single_agent_policy(
    agent_pos: Tuple[float, float],
    agent_fire_reduction_power: float,
    agent_suppressant_num: float,
    other_agents_pos: List[Tuple[float, float]],
    fire_pos: List[Tuple[float, float]],
    fire_levels: List[int],
    fire_intensities: List[float],
    fire_putout_weight: List[float],
) -> int:
    num_tasks = len(fire_pos)
    best_task_score = float('-inf')
    selected_task_index = -1

    # Parameter for policy tuning
    distance_temperature = 0.004  # Further attenuation in distance impact
    intensity_temperature = 0.015  # Slightly increase to offer more impact from high intensive fires
    suppressant_conserve_factor = 20.0  # Further emphasis on saving suppressant

    remaining_suppressant = np.exp(-suppressant_conserve_factor * (1 - (agent_suppressant_num / 10)))

    for i in range(num_tasks):
        distance = np.sqrt((agent_pos[0] - fire_pos[i][0])**2 + (agent_pos[1] - fire_pos[i][1])**2)
        norm_distance = np.exp(-distance_temperature * distance)

        intensity = fire_intensities[i] * fire_levels[i]
        norm_intensity = np.exp(-intensity_temperature * intensity)

        # Fine-tune score to balance fire control and resource management
        score = fire_putout_weight[i] * (norm_distance * agent_fire_reduction_power / (1 + intensity)) * np.log1p(fire_levels[i]) * remaining_suppressant * norm_intensity

        if score > best_task_score:
            best_task_score = score
            selected_task_index = i

    return selected_task_index
```
These adjustments in the proposed policy function aim to make better decisions related to fire-fighting tasks by considering distance, fire intensity, and efficient usage of the suppressant. By carefully tuning the parameters, the function strives to achieve a balance between handling fires effectively and conservively using resources.