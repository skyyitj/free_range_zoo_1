After reviewing the performance metrics, it's clear there's still room for improvements. The average rewards could be higher, and the Suppressant efficiency could be more optimized. 

The metrics suggest that the policy currently prioritizes a higher number of fires extinguished at the cost of resource efficiency.

Let's adjust some parameters and evaluate the impact:

- We will use a lower `suppressant_conserve_factor` to allow the agent to use more suppressants when needed. 

- Additionally, we will adjust `intensity_temperature` to prioritize more severe fires. 

- Lastly, we can adjust `distance_temperature` upward to bias closer fires.

The updated policy function with these changes looks like this:

```python
import numpy as np

def single_agent_policy(
    agent_pos: Tuple[float, float],
    agent_fire_reduction_power: float,
    agent_suppressant_num: float,
    other_agents_pos: List[Tuple[float, float]],
    fire_pos: List[Tuple[float, float]],
    fire_levels: List[int],
    fire_intensities: List[float],
    fire_putout_weight: List[float],
) -> int:
    num_tasks = len(fire_pos)
    best_task_score = float('-inf')
    selected_task_index = -1

    # Parameter for policy tuning
    distance_temperature = 0.01  # Further upward change in distance temperature
    intensity_temperature = 0.03  # Increase to allow more impact from high intensive fires
    suppressant_conserve_factor = 12.0  # Reduce to allow more usage of suppressant

    remaining_suppressant = np.exp(-suppressant_conserve_factor * (1 - (agent_suppressant_num / 10)))

    for i in range(num_tasks):
        distance = np.sqrt((agent_pos[0] - fire_pos[i][0])**2 + (agent_pos[1] - fire_pos[i][1])**2)
        norm_distance = np.exp(-distance_temperature * distance)

        intensity = fire_intensities[i] * fire_levels[i]
        norm_intensity = np.exp(-intensity_temperature * intensity)

        # Fine-tune score to balance fire control and resource management
        score = fire_putout_weight[i] * (norm_distance * agent_fire_reduction_power / (1 + intensity)) * np.log1p(fire_levels[i]) * remaining_suppressant * norm_intensity

        if score > best_task_score:
            best_task_score = score
            selected_task_index = i

    return selected_task_index
```
This revised policy function will still select fire tasks based on their weighted score, but the modified parameters should improve overall fire control and resource efficiency. The adjustments aim to decrease average burning numbers and used suppressants and to increase the average rewards and putout numbers.