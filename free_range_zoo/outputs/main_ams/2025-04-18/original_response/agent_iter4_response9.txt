```python
def single_agent_policy(
    agent_pos: Tuple[float, float], 
    agent_fire_reduction_power: float, 
    agent_suppressant_num: float, 

    other_agents_pos: List[Tuple[float, float]], 

    fire_pos: List[Tuple[float, float]], 
    fire_levels: List[int], 
    fire_intensities: List[float], 

    fire_putout_weight: List[float]
) -> int:

    # === Scoring Fire Tasks ===
    max_score = float('-inf')
    best_fire = None
    
    # modify the temperature parameter to adjust the balance of the metrics
    temperature = 0.5  

    for i, (fire_position, fire_level, fire_intensity, fire_weight) in enumerate(zip(fire_pos, fire_levels, fire_intensities, fire_putout_weight)):

        dist = ((fire_position[0]-agent_pos[0])**2 + (fire_position[1]-agent_pos[1])**2)**0.5 / (agent_suppressant_num+1)

        # modify the suppression_power to consider the fire_level factor
        suppression_power = agent_fire_reduction_power * agent_suppressant_num * fire_level / (fire_intensity + 1)  

        score = np.exp((fire_weight * suppression_power / (dist + 1)) / temperature)

        if score > max_score:
            max_score = score
            best_fire = i

    return best_fire
```

In the revised policy, we adjust the temperature and suppression_power for balancing the influence of the factors. We increase the temperature to make the grading less extreme and increase the influence of fire_level in suppression power. This can make the agents choose the fire task with higher level and smaller distance, and in the meantime, the suppressant resources are used more efficiently.