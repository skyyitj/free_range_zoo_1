```python
def single_agent_policy(
    agent_pos: Tuple[float, float], 
    agent_fire_reduction_power: float, 
    agent_suppressant_num: float, 

    other_agents_pos: List[Tuple[float, float]], 

    fire_pos: List[Tuple[float, float]], 
    fire_levels: List[int], 
    fire_intensities: List[float], 

    fire_putout_weight: List[float]
) -> int:

    # === Scoring Fire Tasks ===
    max_score = float('-inf')
    best_fire = None
    temperature = 0.05  # Lower the temperature parameter to further amplify the score differences

    for i, (fire_position, fire_level, fire_intensity, fire_weight) in enumerate(zip(fire_pos, fire_levels, fire_intensities, fire_putout_weight)):

        # Distance-based factor for task selection
        dist = ((fire_position[0]-agent_pos[0])**2 + (fire_position[1]-agent_pos[1])**2)**0.5 / (agent_suppressant_num+1)

        # Firefighting efficiency factor in task selection
        suppression_power = agent_fire_reduction_power * agent_suppressant_num / (fire_intensity + 1)

        # Score calculation considering prioritization weight, firefighting efficiency, and distance factor
        # Include the fire level as an additional factor to prioritize fires with higher levels
        score = np.exp((fire_weight * suppression_power / (dist + 1) + 2 * fire_level) / temperature)

        if score > max_score:
            max_score = score
            best_fire = i

    return best_fire
```
In the revised policy, we decrease the temperature parameter, which makes the differentiation in scores more significant. This can help the agent make a more decisive choice. Also, we double the weight of the fire level in the score calculation because the evaluation results show a relatively high number of burned-out fires, which indicates that the agent may not adequately prioritize fires with higher levels. The revised policy places more emphasis on the fire level, which can help the agent reduce the number of burned-out fires and thereby improve overall performance.