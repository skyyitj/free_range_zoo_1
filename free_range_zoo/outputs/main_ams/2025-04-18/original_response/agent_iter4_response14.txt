```python
def single_agent_policy(
    agent_pos: Tuple[float, float], 
    agent_fire_reduction_power: float, 
    agent_suppressant_num: float, 

    other_agents_pos: List[Tuple[float, float]], 

    fire_pos: List[Tuple[float, float]], 
    fire_levels: List[int], 
    fire_intensities: List[float], 

    fire_putout_weight: List[float]
) -> int:

    # === Scoring Fire Tasks ===
    max_score = float('-inf')
    best_fire = None

    temperature_distance = 0.5  # introduce a temperature parameter to adjust the distance factor
    temperature_suppression = 0.2  # introduce a temperature parameter to adjust the suppression power factor
    temperature_level = 0.3  # introduce a temperature parameter to adjust the fire level factor

    for i, (fire_position, fire_level, fire_intensity, fire_weight) in enumerate(zip(fire_pos, fire_levels, fire_intensities, fire_putout_weight)):

        # Distance-based factor for task selection
        dist = ((fire_position[0]-agent_pos[0])**2 + (fire_position[1]-agent_pos[1])**2)**0.5 / (agent_suppressant_num+1)
        dist_factor = np.exp(-dist/temperature_distance)

        # Firefighting efficiency factor in task selection
        suppression_power = agent_fire_reduction_power * agent_suppressant_num / (fire_intensity + 1)
        suppression_factor = np.exp(suppression_power/temperature_suppression)

        # Level-based factor for task selection
        level_factor = np.exp(fire_level/temperature_level)

        # Score calculation considering prioritization weight, firefighting efficiency, and distance factor
        score = fire_weight * suppression_factor * dist_factor * level_factor

        if score > max_score:
            max_score = score
            best_fire = i

    return best_fire
```
In the revised policy, we introduce separate temperature for the distance, suppression power and fire level factors. It allows us to control and adjust the impact of each factor individually, allowing us to come up with a balanced strategy.