```python
def single_agent_policy(       
    agent_pos: Tuple[float, float],              
    agent_fire_reduction_power: float,           
    agent_suppressant_num: float,               

    other_agents_pos: List[Tuple[float, float]], 

    fire_pos: List[Tuple[float, float]],         
    fire_levels: List[int], 
    fire_intensities: List[float], 

    fire_putout_weight: List[float]
) -> int:

    # === Adjusting Scoring Criteria ===
    max_score = -float('inf')
    best_fire = None

    dist_temperature = 0.1  # Adjust temperature coefficient to balance distance factor
    suppress_power_temperature = 0.15  # Adjust temperature coefficient to balance suppression power factor

    for i, (fire_position, fire_level, fire_intensity, fire_weight) in enumerate(zip(fire_pos, fire_levels, fire_intensities, fire_putout_weight)):

        # Distance factor with higher weight
        dist = ((fire_position[0]-agent_pos[0])**2 + (fire_position[1]-agent_pos[1])**2)**0.5 / (agent_suppressant_num+1)

        # Firefighting efficiency factor with lower weight
        suppression_power = agent_fire_reduction_power * agent_suppressant_num / (fire_intensity+1)

        # Score calculation considering prioritization weight, firefighting efficiency, and distance factor
        score = np.exp((fire_weight * suppression_power / (dist_temperature * dist + 1) + fire_level) / suppress_power_temperature)

        if score > max_score:
            max_score = score
            best_fire = i

    return best_fire
```
This policy function improves on the previous policy function by reducing the temperature coefficient of the distance factor and increasing the temperature of the suppressant power factor. These changes help balance the prioritization of tasks based on their distance and the agent's current suppressant resources. By making distance a less dominant factor, agents can better allocate their resources to extinguish more intense fires, even if they are farther away. It is expected that these adjustments will improve the metrics of “average fire intensity change rate”, “average suppressant use” and “average reward”. In addition, to avoid agents wasting resources on fires close to them that other agents are also managing, the new policy includes a normalization function to balance the suppressant use against the fire intensity. This adjustment will help improve the “average suppressant use” metric.