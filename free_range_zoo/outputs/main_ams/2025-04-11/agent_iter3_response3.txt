/home/liuchi/miniconda3/envs/zymatch/lib/python3.12/site-packages/torch/nested/__init__.py:109: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)
  return torch._nested_tensor_from_tensor_list(ts, dtype, None, device, None)
workspace_dir: /home/liuchi/yitianjiao/aamas2025/free-range-zoo/free_range_zoo/outputs/main_ams/2025-04-11
Test 1 results:
  - Fire Intensity Change per step: -1.33
  - Total Rewards: 6.00
  - Suppressant Efficiency: 0.0000 intensity/suppressant
Test 2 results:
  - Fire Intensity Change per step: -0.67
  - Total Rewards: 9.00
  - Suppressant Efficiency: 0.0000 intensity/suppressant
Test 3 results:
  - Fire Intensity Change per step: -0.50
  - Total Rewards: 9.00
  - Suppressant Efficiency: 1.3333 intensity/suppressant
Test 4 results:
  - Fire Intensity Change per step: -0.40
  - Total Rewards: 9.00
  - Suppressant Efficiency: 1.3333 intensity/suppressant
Test 5 results:
  - Fire Intensity Change per step: -0.33
  - Total Rewards: 9.00
  - Suppressant Efficiency: 1.3333 intensity/suppressant
Test 6 results:
  - Fire Intensity Change per step: -0.27
  - Total Rewards: 9.00
  - Suppressant Efficiency: 0.0000 intensity/suppressant
Test 7 results:
  - Fire Intensity Change per step: -0.24
  - Total Rewards: 9.00
  - Suppressant Efficiency: 1.3333 intensity/suppressant
Traceback (most recent call last):
  File "/home/liuchi/yitianjiao/aamas2025/free-range-zoo/free_range_zoo/experiments/train.py", line 130, in <module>
    agent_name: agents[agent_name].act(action_space=env.action_space(agent_name))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liuchi/yitianjiao/aamas2025/free-range-zoo/free_range_zoo/envs/wildfire/baselines/generated_agent.py", line 97, in act
    maximum_index = single_agent_policy(agent_pos, agent_fire_power, agent_suppressant_num, other_agents_pos,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liuchi/yitianjiao/aamas2025/free-range-zoo/free_range_zoo/envs/wildfire/baselines/generated_agent.py", line 158, in single_agent_policy
    agent_counts = Counter([np.argmin([np.sqrt((ag[0]-fire[0])**2 + (ag[1]-fire[1])**2) for fire in fire_pos])+1 for ag in other_agents_pos])
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liuchi/miniconda3/envs/zymatch/lib/python3.12/site-packages/numpy/_core/fromnumeric.py", line 1440, in argmin
    return _wrapfunc(a, 'argmin', axis=axis, out=out, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liuchi/miniconda3/envs/zymatch/lib/python3.12/site-packages/numpy/_core/fromnumeric.py", line 54, in _wrapfunc
    return _wrapit(obj, method, *args, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liuchi/miniconda3/envs/zymatch/lib/python3.12/site-packages/numpy/_core/fromnumeric.py", line 46, in _wrapit
    result = getattr(arr, method)(*args, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: attempt to get argmin of an empty sequence
