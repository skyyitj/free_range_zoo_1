In the previous policy, we used np.exp() function to change the scale of distance, fire_levels and fire_intensities. After  reviewing the results from the evaluation run, we conclude that there might be a need to adjust the temperature values used in scaling down these factors. The task selection should consider the reward weight in a more prominent way. Therefore, we use the reward weight as an exponential factor to improve performances. 

```python
import numpy as np
from typing import List, Tuple
from scipy.spatial import distance

def single_agent_policy(
    # === Agent Properties ===
    agent_pos: Tuple[float, float],              # Current position of the agent (y, x)
    agent_fire_reduction_power: float,           # How much fire the agent can reduce
    agent_suppressant_num: float,                # Amount of fire suppressant available
 
    # === Team Information ===
    other_agents_pos: List[Tuple[float, float]], # Positions of all other agents [(y1, x1), (y2, x2), ...]

    # === Fire Task Information ===
    fire_pos: List[Tuple[float, float]],         # Locations of all fires [(y1, x1), (y2, x2), ...]
    fire_levels: List[int],                    # Current intensity level of each fire
    fire_intensities: List[float],               # Current intensity value of each fire task
 
    # === Task Prioritization ===
    fire_putout_weight: List[float],             # Priority weights for fire suppression tasks
) -> int:
    
    num_tasks = len(fire_levels)
    scores = np.zeros(num_tasks)
 
    can_put_out_fire = agent_suppressant_num * agent_fire_reduction_power

    # decrease the temperature parameters
    level_temperature = 0.03
    intensity_temperature = 0.03
    distance_temperature = 0.007
 
    for task in range(num_tasks):
 
        # get euclidean distance between fire and agent
        fire_distance = distance.euclidean(agent_pos, fire_pos[task])
 
        # calculate score for each task using fire intensity, level, and distance
        # all values are multiplied by suppressant-amount to penalize lower resources
        # the reward-weights are applied as an exponential factor to prioritize tasks
        scores[task] = (
            np.exp(-fire_levels[task] * level_temperature) +
            np.exp(-fire_intensities[task] / can_put_out_fire * intensity_temperature) -
            np.exp(fire_distance * distance_temperature)) ** fire_putout_weight[task]
 
    # return the index of the task with the highest score
    max_score_task = np.argmax(scores)
    return max_score_task
```
This revised policy function adjusts the temperature parameters, placing a heavier weighting on the steps of suppressing the most intense fires and being closer to fires. The evaluation of this policy should result in improvements in the metrics for total rewards and fire intensity change.