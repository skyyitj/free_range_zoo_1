Revising the policy function to focus more effectively on putting out the fires can be achieved by adjusting the temperature parameters and perhaps altering how we combine the different scores. The new policy function should try to maximize both effectiveness (using less suppressant for more impact) and prioritize critical fires more appropriately.

Here's an updated policy function:

```python
import numpy as np

def single_agent_policy(
    agent_pos: Tuple[float, float], 
    agent_fire_reduction_power: float,
    agent_suppressant_num: float, 
    other_agents_pos: List[Tuple[float, float]], 
    fire_pos: List[Tuple[float, float]], 
    fire_levels: List[int], 
    fire_intensities: List[float],
    fire_putout_weight: List[float]
) -> int:
    num_tasks = len(fire_pos)
    best_task_index = -1
    highest_score = float('-inf')
    
    # Score for each task based on criteria
    for task_index in range(num_tasks):
        # Fire Position and Intensity
        fire = fire_pos[task_index]
        fire_level = fire_levels[task_index]
        fire_intensity = fire_intensities[task_index]
        
        # Calculate distance from agent to fire
        distance = np.sqrt((agent_pos[0] - fire[0]) ** 2 + (agent_pos[1] - fire[1]) ** 2)
        
        # Effectiveness of the agent on this fire task
        potential_suppress_effect = agent_fire_reduction_power * min(agent_suppressant_num, fire_intensity / agent_fire_reduction_power)
        
        # Calculate the weighted attractiveness of tackling this fire based on potential effect and priority weight
        importance_weight = fire_putout_weight[task_index]
        
        # Adjust the temperature parameters to alter the balance of factors (revised based on performance analysis)
        distance_temp = 1.0  # Assign more sensitivity to distance to avoid overly distant engagements
        effect_temp = 1.0    # Keep the impact of suppression efficiency
        weight_temp = 0.3    # Increase the importance of fire task weight to address more critical fire levels aggressively
        
        # Revised score computation with adjusted temperature scaling
        task_score = (
            -np.exp(distance / distance_temp) + # Smaller distance preferred, negative exponential to make closer task score higher
            np.exp(potential_suppress_effect / effect_temp) +
            np.exp(importance_weight / weight_temp)
        )
        
        # Update the selection if the current task has a higher score
        if task_score > highest_score:
            highest_score = task_score
            best_task_index = task_index
    
    return best_task_index
```

This revision:
1. Lowered the temperature for distance, making the agent more sensitive to distance.
2. Significantly lowered the temperature for the priority weight, making the agents focus more on heavily weighted tasks which are typically more critical or rewarding.
3. Kept the effect temperature unchanged as it seemed effectively balanced according to presented results.

These adjustments should help improve the effectiveness of resource usage and increase the urgency in handling higher priority fires.