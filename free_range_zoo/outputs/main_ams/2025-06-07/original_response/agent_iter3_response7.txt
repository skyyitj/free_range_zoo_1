```python
def single_agent_policy(
    agent_pos,
    agent_fire_reduction_power,
    agent_supressant_num,
    other_agents_pos,
    fire_pos,
    fire_levels,
    fire_intensities,
    fire_putout_weight
):
    import numpy as np

    # Calculate distances of the agent to each fire
    distances = [
        np.sqrt((f_pos[0] - agent_pos[0]) ** 2 + (f_pos[1] - agent_pos[1]) ** 2)
        for f_pos in fire_pos
    ]

    # Normalize distances to prioritize nearby fires
    normalized_distances = 1 / (np.array(distances) + 0.01)  # Add a small value to avoid division by zero

    # Calculate potential suppressant effect on each fire
    suppressant_effect = np.array(fire_levels) - (agent_supressant_num * agent_fire_reduction_power / np.array(fire_intensities))

    # Fires we expect to extinguish with current agent, we weight them highly
    extinguishable_fires = suppressant_effect <= 0

    # Convert all positive effects into the capacity of reduction, scale down non-extinguishable
    suppressant_effect[~extinguishable_fires] = 0

    # Normalize the suppressant effects
    max_effect = np.max(suppressant_effect) if np.max(suppressant_effect) > 0 else 1
    normalized_effects = suppressant_effect / max_effect

    # Aggregate scores by combining distances, effects, and task weights
    scores = normalized_distances * (fire_putout_weight * normalized_effects)

    # Boost scores for extinguishable fires
    scores[extinguishable_fires] *= 2

    # Selection of the fire task with the highest score
    selected_task_index = np.argmax(scores)

    return selected_task_index
```